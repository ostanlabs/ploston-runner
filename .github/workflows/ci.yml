# =============================================================================
# Ploston Runner CI Workflow
# =============================================================================
# Runs lint and unit tests, reports to meta-repo.
#
# Triggers:
#   - Push to main: Full CI + trigger meta-repo integration tests
#   - Pull request: Lint + unit tests only
#   - workflow_dispatch: Triggered by meta-repo for coordinated builds
# =============================================================================

name: CI

on:
  push:
    branches: [main]
  pull_request:
  workflow_dispatch:
    inputs:
      ploston_core_version:
        description: 'ploston-core version to use (PyPI version like 1.4.0.dev1738800000). Empty = latest PyPI'
        required: false
        default: ''
      meta_run_id:
        description: 'Meta-repo run ID (for callback)'
        required: false
        default: ''

# Prevent concurrent runs on the same branch/ref
concurrency:
  group: ci-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Run lint
        run: make lint

  unit-tests:
    needs: lint
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Create venv and install dependencies
        run: |
          uv venv
          uv sync --all-extras

      - name: Wait for ploston-core on PyPI
        if: inputs.ploston_core_version != ''
        env:
          GH_TOKEN: ${{ secrets.META_REPO_TOKEN }}
        run: |
          # Fetch the wait script from meta-repo
          curl -sL \
            -H "Authorization: token ${GH_TOKEN}" \
            -H "Accept: application/vnd.github.v3.raw" \
            "https://api.github.com/repos/ostanlabs/agent-execution-layer/contents/ci/scripts/wait-for-pypi.sh?ref=main" \
            -o wait-for-pypi.sh
          chmod +x wait-for-pypi.sh
          ./wait-for-pypi.sh ploston-core "${{ inputs.ploston_core_version }}"

      - name: Install specific ploston-core version
        if: inputs.ploston_core_version != ''
        run: uv pip install "ploston-core==${{ inputs.ploston_core_version }}"

      - name: Run unit tests
        run: uv run pytest tests/unit/ -v --tb=short --junitxml=junit-results.xml

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: junit-results.xml

  # ===========================================================================
  # Report Results to Meta-Repo
  # ===========================================================================
  # When triggered by workflow_dispatch (from meta-repo), we don't send any event
  # back - the meta-repo uses `gh run watch` to wait for completion.
  #
  # When triggered by push to main (organic change), we send component-updated
  # to trigger the full meta-repo CI pipeline.
  # ===========================================================================

  # Trigger meta-repo CI when this repo changes organically (push to main)
  trigger-meta-repo:
    needs: unit-tests
    if: github.event_name == 'push' && github.ref == 'refs/heads/main' && needs.unit-tests.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Trigger meta-repo CI
        uses: peter-evans/repository-dispatch@v3
        with:
          token: ${{ secrets.META_REPO_TOKEN }}
          repository: ostanlabs/agent-execution-layer
          event-type: component-updated
          client-payload: |
            {
              "trigger_repo": "ploston-runner",
              "trigger_sha": "${{ github.sha }}"
            }

  report-to-dashboard:
    name: Report to Dashboard
    runs-on: ubuntu-latest
    timeout-minutes: 5
    continue-on-error: true
    needs: [lint, unit-tests]
    if: always() && github.ref == 'refs/heads/main'
    steps:
      - name: Download test results
        uses: actions/download-artifact@v4
        continue-on-error: true
        with:
          name: test-results
          path: test-results/

      - name: Parse test results
        id: parse
        run: |
          TOTAL_TESTS=0
          TOTAL_PASSED=0
          TOTAL_FAILED=0
          TOTAL_SKIPPED=0

          if [ -d "test-results" ]; then
            for xml in test-results/*.xml; do
              if [ -f "$xml" ]; then
                TESTS=$(grep -oP 'tests="\K[0-9]+' "$xml" | head -1 || echo 0)
                FAILURES=$(grep -oP 'failures="\K[0-9]+' "$xml" | head -1 || echo 0)
                ERRORS=$(grep -oP 'errors="\K[0-9]+' "$xml" | head -1 || echo 0)
                SKIPPED=$(grep -oP 'skipped="\K[0-9]+' "$xml" | head -1 || echo 0)

                TOTAL_TESTS=$((TOTAL_TESTS + TESTS))
                TOTAL_FAILED=$((TOTAL_FAILED + FAILURES + ERRORS))
                TOTAL_SKIPPED=$((TOTAL_SKIPPED + SKIPPED))
              fi
            done
          fi

          TOTAL_PASSED=$((TOTAL_TESTS - TOTAL_FAILED - TOTAL_SKIPPED))

          echo "total=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "passed=$TOTAL_PASSED" >> $GITHUB_OUTPUT
          echo "failed=$TOTAL_FAILED" >> $GITHUB_OUTPUT
          echo "skipped=$TOTAL_SKIPPED" >> $GITHUB_OUTPUT

      - name: Get short SHA
        id: sha
        run: echo "short=${GITHUB_SHA::7}" >> $GITHUB_OUTPUT

      - name: Report to meta-repo dashboard
        uses: peter-evans/repository-dispatch@v3
        with:
          token: ${{ secrets.META_REPO_TOKEN }}
          repository: ostanlabs/agent-execution-layer
          event-type: ci-results-ploston-runner
          client-payload: |
            {
              "package": "ploston-runner",
              "sha": "${{ github.sha }}",
              "short_sha": "${{ steps.sha.outputs.short }}",
              "run_id": "${{ github.run_id }}",
              "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
              "lint": "${{ needs.lint.result }}",
              "test": "${{ needs.unit-tests.result }}",
              "tests": {
                "total": ${{ steps.parse.outputs.total }},
                "passed": ${{ steps.parse.outputs.passed }},
                "failed": ${{ steps.parse.outputs.failed }},
                "skipped": ${{ steps.parse.outputs.skipped }}
              },
              "status": "${{ needs.lint.result == 'success' && needs.unit-tests.result == 'success' && 'success' || 'failure' }}"
            }
