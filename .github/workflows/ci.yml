name: CI

on:
  push:
    branches: [main]
  pull_request:
    branches: [main]
  workflow_dispatch:
  repository_dispatch:
    types: [core-updated]

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Set up Python
        run: uv python install 3.12

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run ruff check
        run: uv run ruff check src/ tests/

      - name: Run ruff format check
        run: uv run ruff format --check src/ tests/

  unit-tests:
    name: Unit Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.12", "3.13"]
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Set up Python ${{ matrix.python-version }}
        run: uv python install ${{ matrix.python-version }}

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run unit tests
        run: |
          uv run pytest tests/unit/ -v \
            --cov=ploston_runner \
            --cov-report=xml \
            --cov-report=html \
            --junitxml=junit-unit-${{ matrix.python-version }}.xml

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results-${{ matrix.python-version }}
          path: junit-unit-${{ matrix.python-version }}.xml

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        if: matrix.python-version == '3.12'
        with:
          name: coverage-report
          path: htmlcov/

  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Set up Python
        run: uv python install 3.12

      - name: Install dependencies
        run: uv sync --all-extras

      - name: Run integration tests
        run: |
          uv run pytest tests/integration/ -v \
            --junitxml=junit-integration.xml \
            || echo "No integration tests found or tests skipped"
        continue-on-error: true

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results
          path: junit-integration.xml
          if-no-files-found: ignore

  test-summary:
    name: Test Summary
    needs: [unit-tests, integration-tests]
    runs-on: ubuntu-latest
    if: always()
    permissions:
      contents: read
      checks: write
      pull-requests: write
    steps:
      - name: Download unit test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          path: test-results/
          merge-multiple: true

      - name: Download integration test results
        uses: actions/download-artifact@v4
        with:
          name: integration-test-results
          path: test-results/
        continue-on-error: true

      - name: Publish Test Summary
        uses: EnricoMi/publish-unit-test-result-action@v2
        if: always()
        with:
          files: test-results/**/*.xml
          comment_mode: always
          check_name: Test Results
          compare_to_earlier_commit: false

  report-to-dashboard:
    name: Report to Dashboard
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: always() && github.ref == 'refs/heads/main'
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: "*-test-results*"
          path: test-results/
          merge-multiple: true

      - name: Parse test results
        id: parse
        run: |
          # Count tests from JUnit XML files
          TOTAL_TESTS=0
          TOTAL_PASSED=0
          TOTAL_FAILED=0
          TOTAL_SKIPPED=0

          for xml in test-results/*.xml; do
            if [ -f "$xml" ]; then
              TESTS=$(grep -oP 'tests="\K[0-9]+' "$xml" | head -1 || echo 0)
              FAILURES=$(grep -oP 'failures="\K[0-9]+' "$xml" | head -1 || echo 0)
              ERRORS=$(grep -oP 'errors="\K[0-9]+' "$xml" | head -1 || echo 0)
              SKIPPED=$(grep -oP 'skipped="\K[0-9]+' "$xml" | head -1 || echo 0)

              TOTAL_TESTS=$((TOTAL_TESTS + TESTS))
              TOTAL_FAILED=$((TOTAL_FAILED + FAILURES + ERRORS))
              TOTAL_SKIPPED=$((TOTAL_SKIPPED + SKIPPED))
            fi
          done

          TOTAL_PASSED=$((TOTAL_TESTS - TOTAL_FAILED - TOTAL_SKIPPED))

          echo "total=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "passed=$TOTAL_PASSED" >> $GITHUB_OUTPUT
          echo "failed=$TOTAL_FAILED" >> $GITHUB_OUTPUT
          echo "skipped=$TOTAL_SKIPPED" >> $GITHUB_OUTPUT

      - name: Report to meta-repo dashboard
        uses: peter-evans/repository-dispatch@v2
        with:
          token: ${{ secrets.META_REPO_TOKEN }}
          repository: ostanlabs/agent-execution-layer
          event-type: ci-results
          client-payload: |
            {
              "package": "ploston-runner",
              "sha": "${{ github.sha }}",
              "short_sha": "${{ github.sha }}",
              "run_id": "${{ github.run_id }}",
              "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
              "tests": {
                "total": ${{ steps.parse.outputs.total }},
                "passed": ${{ steps.parse.outputs.passed }},
                "failed": ${{ steps.parse.outputs.failed }},
                "skipped": ${{ steps.parse.outputs.skipped }}
              },
              "status": "${{ needs.unit-tests.result == 'success' && needs.integration-tests.result == 'success' && 'success' || 'failure' }}"
            }

  build:
    name: Build
    runs-on: ubuntu-latest
    needs: [lint, unit-tests]
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4

      - name: Set up Python
        run: uv python install 3.12

      - name: Build package
        run: uv build

      - name: Check package installable
        run: |
          uv venv .test-venv
          uv pip install --python .test-venv dist/*.whl
          uv run --python .test-venv python -c "import ploston_runner; print(ploston_runner.__name__)"

      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist
          path: dist/

  notify-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [lint, unit-tests, integration-tests, build]
    if: failure() && github.ref == 'refs/heads/main'
    steps:
      - name: Send Slack notification
        uses: slackapi/slack-github-action@v2.0.0
        with:
          webhook: ${{ secrets.SLACK_WEBHOOK_URL }}
          webhook-type: incoming-webhook
          payload: |
            {
              "text": "❌ CI Failed: ploston-runner",
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "❌ CI Failed: ploston-runner"
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Repository:*\n<${{ github.server_url }}/${{ github.repository }}|${{ github.repository }}>"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Branch:*\n${{ github.ref_name }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Commit:*\n<${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }}|${{ github.sha }}>"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Author:*\n${{ github.actor }}"
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "View Run"
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
