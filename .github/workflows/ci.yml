# =============================================================================
# Ploston Runner CI Workflow
# =============================================================================
# Runs unit tests locally, then triggers meta-repo for integration tests.
# =============================================================================

name: CI

on:
  push:
    branches: [main]
  pull_request:

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install pre-commit
        run: pip install pre-commit

      - name: Run pre-commit
        run: pre-commit run --all-files --show-diff-on-failure

  unit-tests:
    needs: lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install -e .[dev]

      - name: Run unit tests
        run: |
          pytest tests/unit/ -v --tb=short \
            --junitxml=junit-results.xml

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: junit-results.xml

  trigger-integration:
    needs: unit-tests
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Trigger meta-repo CI
        uses: peter-evans/repository-dispatch@v3
        with:
          token: ${{ secrets.META_REPO_TOKEN }}
          repository: ostanlabs/agent-execution-layer
          event-type: component-updated
          client-payload: |
            {
              "trigger_repo": "ploston-runner",
              "trigger_sha": "${{ github.sha }}"
            }

  report-to-dashboard:
    name: Report to Dashboard
    runs-on: ubuntu-latest
    needs: [lint, unit-tests]
    if: always() && github.ref == 'refs/heads/main'
    steps:
      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          name: test-results
          path: test-results/

      - name: Parse test results
        id: parse
        run: |
          TOTAL_TESTS=0
          TOTAL_PASSED=0
          TOTAL_FAILED=0
          TOTAL_SKIPPED=0

          for xml in test-results/*.xml; do
            if [ -f "$xml" ]; then
              TESTS=$(grep -oP 'tests="\K[0-9]+' "$xml" | head -1 || echo 0)
              FAILURES=$(grep -oP 'failures="\K[0-9]+' "$xml" | head -1 || echo 0)
              ERRORS=$(grep -oP 'errors="\K[0-9]+' "$xml" | head -1 || echo 0)
              SKIPPED=$(grep -oP 'skipped="\K[0-9]+' "$xml" | head -1 || echo 0)

              TOTAL_TESTS=$((TOTAL_TESTS + TESTS))
              TOTAL_FAILED=$((TOTAL_FAILED + FAILURES + ERRORS))
              TOTAL_SKIPPED=$((TOTAL_SKIPPED + SKIPPED))
            fi
          done

          TOTAL_PASSED=$((TOTAL_TESTS - TOTAL_FAILED - TOTAL_SKIPPED))

          echo "total=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "passed=$TOTAL_PASSED" >> $GITHUB_OUTPUT
          echo "failed=$TOTAL_FAILED" >> $GITHUB_OUTPUT
          echo "skipped=$TOTAL_SKIPPED" >> $GITHUB_OUTPUT

      - name: Get short SHA
        id: sha
        run: echo "short=${GITHUB_SHA::7}" >> $GITHUB_OUTPUT

      - name: Report to meta-repo dashboard
        uses: peter-evans/repository-dispatch@v3
        with:
          token: ${{ secrets.META_REPO_TOKEN }}
          repository: ostanlabs/agent-execution-layer
          event-type: ci-results-ploston-runner
          client-payload: |
            {
              "package": "ploston-runner",
              "sha": "${{ github.sha }}",
              "short_sha": "${{ steps.sha.outputs.short }}",
              "run_id": "${{ github.run_id }}",
              "run_url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
              "lint": "${{ needs.lint.result }}",
              "test": "${{ needs.unit-tests.result }}",
              "tests": {
                "total": ${{ steps.parse.outputs.total }},
                "passed": ${{ steps.parse.outputs.passed }},
                "failed": ${{ steps.parse.outputs.failed }},
                "skipped": ${{ steps.parse.outputs.skipped }}
              },
              "status": "${{ needs.lint.result == 'success' && needs.unit-tests.result == 'success' && 'success' || 'failure' }}"
            }
